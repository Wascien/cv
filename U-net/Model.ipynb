{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb674ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from DataModel import SegmentationData,base_image_path,base_imge_name,base_label_path,base_label_name,base_path\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv_relu = nn.Sequential(\n",
    "            nn.Conv2d(middle_channels, out_channels, kernel_size=3,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "  \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "       \n",
    "        x1 = torch.cat((x1, x2), dim=1)\n",
    "        x1 = self.conv_relu(x1)\n",
    "        return x1\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,use_maxpool=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        layers=[]\n",
    "        \n",
    "        if use_maxpool==True:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        \n",
    "        layers+=[\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        self.net=nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        return self.net(X)\n",
    "\n",
    "    \n",
    "encoder_params=((3,64,False),(64,128),(128,256),(256,512),(512,1024))    \n",
    "decoder_params=((1024,1024,512),(512,512,256),(256,256,128),(128,128,64)) \n",
    "class U_net(nn.Module):\n",
    "    def __init__(self,encoder_params,decoder_params):\n",
    "        super().__init__()\n",
    "        maxpools=[]\n",
    "        encoders=[]\n",
    "        for param in encoder_params:\n",
    "            encoders.append(Encoder(*param))\n",
    "            maxpools.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "            \n",
    "        decoders=[]\n",
    "        for param in decoder_params:\n",
    "            decoders.append(Decoder(*param))\n",
    "        \n",
    "        self.encoders=nn.Sequential(*encoders)\n",
    "        self.decoders=nn.Sequential(*decoders)\n",
    "        self.finalconv=nn.Conv2d(64,21,kernel_size=1)\n",
    "       \n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "\n",
    "        x0=self.encoders[0](X)\n",
    "        #print(x0.shape)\n",
    "        x1=self.encoders[1](x0)\n",
    "        #print(x1.shape)\n",
    "        x2=self.encoders[2](x1)\n",
    "        #print(x2.shape)\n",
    "        x3=self.encoders[3](x2)\n",
    "        #print(x3.shape)\n",
    "        x4=self.encoders[4](x3)\n",
    "        #print(x4.shape)\n",
    "        e3=x3[:,:,4:60,4:60]\n",
    "        x5=self.decoders[0](x4,e3)\n",
    "        #print(x5.shape)\n",
    "        e2=x2[:,:,16:120,16:120]\n",
    "        x6=self.decoders[1](x5,e2)\n",
    "        #print(x6.shape)\n",
    "        e1=x1[:,:,40:240,40:240]\n",
    "        x7=self.decoders[2](x6,e1)\n",
    "        e0=x0[:,:,98:490,98:490]\n",
    "        #print(x7.shape)\n",
    "        x8=self.decoders[3](x7,e0)\n",
    "        return self.finalconv(x8)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b6caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=SegmentationData(base_path+'train.txt',base_image_path,base_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf1ee368",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter=DataLoader(data,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57e29d43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net=U_net(encoder_params,decoder_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e401028d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for m in net.modules():\\n    if isinstance(m, (nn.Conv2d, nn.Linear)):\\n        nn.init.xavier_uniform_(m.weight)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precise(test_iter,net,device):\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for X,y in test_iter:\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            y_hat=net(X)\n",
    "            y_hat=torch.argmax(y_hat,dim=-1).flatten()\n",
    "            y=y.flatten()\n",
    "            ans=(y_hat==y)\n",
    "            total+=len(y)\n",
    "            correct+=ans.sum().item()\n",
    "        \n",
    "    print(correct)\n",
    "    print(f\"accuracy :{correct/total*100:>3f}% \")\n",
    "\n",
    "    \n",
    "def train(data_iter,entroy_iter,net,optimizer,lr_scheduler,loss_fn,epochs,device,epoch_data_num):\n",
    "    matrix_x,matrix_loss,entroy_loss,entroy_x=[0],[0],[],[]\n",
    "    total_loss=0\n",
    "    batchs=len(data_iter)\n",
    "    for epoch in range(epochs):\n",
    "        now_num=0\n",
    "        for X,y in data_iter:\n",
    " \n",
    "            now_num+=len(X)\n",
    "    \n",
    "            net.train()\n",
    "            \n",
    "            X,y=X.to(device),y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat=net(X)\n",
    "            y_hat=y_hat.permute(0,2,3,1).flatten(start_dim=0,end_dim=-2)\n",
    "            y=y.flatten()\n",
    "            loss=loss_fn(y_hat,y)\n",
    "            loss.sum().backward()\n",
    "            optimizer.step()\n",
    "            total_loss+=loss.item()\n",
    "            \n",
    "            matrix_x.append(matrix_x[-1]+1)\n",
    "           \n",
    "            correct=(y==torch.argmax(y_hat,dim=-1)).sum().item()\n",
    "            precise=correct*1.0/len(y)            \n",
    "            matrix_loss.append(total_loss/(epoch*epoch_data_num+now_num))\n",
    "            \n",
    "            print(f\"loss: {matrix_loss[-1]:>7f}   accuracy:{precise*100}%   now {matrix_x[-1]}/{batchs*epochs}\" ,end='\\r')\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        torch.save(net.state_dict(), f\"U-net.epoch{epoch+1}.bin\")\n",
    "    return net,matrix_x,matrix_loss,entroy_x,entroy_loss\n",
    "\n",
    "\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net=U_net(encoder_params,decoder_params).to(device)\n",
    "optimizer=Adam(net.parameters(),lr=0.0006)\n",
    "lr_scheduler=LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(2**epoch))\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "'''for m in net.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d4b785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.666768   accuracy:97.45722180890637%   now 78/58566\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _,matrix_x,matrix_loss,entroy_x,entroy_loss\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(data_iter, entroy_iter, net, optimizer, lr_scheduler, loss_fn, epochs, device, epoch_data_num)\u001b[0m\n\u001b[0;32m     28\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     30\u001b[0m X,y\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mto(device),y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 31\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m y_hat\u001b[38;5;241m=\u001b[39mnet(X)\n\u001b[0;32m     33\u001b[0m y_hat\u001b[38;5;241m=\u001b[39my_hat\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,end_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Deeplearning\\lib\\site-packages\\torch\\optim\\optimizer.py:222\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    220\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m foreach \u001b[38;5;129;01mor\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mis_sparse):\n\u001b[1;32m--> 222\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     per_device_and_dtype_grads[p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdevice][p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdtype]\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mgrad)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_,matrix_x,matrix_loss,entroy_x,entroy_loss=train(train_iter,train_iter,net,optimizer,lr_scheduler,loss_fn,4,device,len(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15049603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07196d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
