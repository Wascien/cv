{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3de4cf6",
   "metadata": {},
   "source": [
    "## Inception \n",
    "![](./imgs/inception.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f6035e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.net_0=nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels[0],kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.net_1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels[1][0],kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels[1][0],out_channels[1][1],kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.net_2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels[2][0],kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels[2][0],out_channels[2][1],kernel_size=5,padding=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.net_3=nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3,padding=1,stride=1),\n",
    "            nn.Conv2d(in_channels,out_channels[3],kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "        )        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self,X):\n",
    "        X0=self.net_0(X)\n",
    "        X1=self.net_1(X)\n",
    "        X2=self.net_2(X)\n",
    "        X3=self.net_3(X)\n",
    "        return torch.cat((X0,X1,X2,X3),dim=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fbc20",
   "metadata": {},
   "source": [
    "![](./imgs/inception-full.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a2d6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        net_0=nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        net_1=nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        net_2=nn.Sequential(\n",
    "            Inception(192,[64, (96, 128), (16, 32), 32]),\n",
    "            Inception(256,[128, (128, 192), (32, 96), 64]),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        net_3=nn.Sequential(\n",
    "            Inception(480, [192, (96, 208), (16, 48), 64]),\n",
    "            Inception(512, [160, (112, 224), (24, 64), 64]),\n",
    "            Inception(512, [128, (128, 256), (24, 64), 64]),\n",
    "            Inception(512, [112, (144, 288), (32, 64), 64]),\n",
    "            Inception(528, [256, (160, 320), (32, 128), 128]),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        net_4=nn.Sequential(\n",
    "            Inception(832,[ 256, (160, 320), (32, 128), 128]),\n",
    "            Inception(832,[ 384, (192, 384), (48, 128), 128]),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.net=nn.Sequential(\n",
    "            net_0,net_1,net_2,net_3,net_4,nn.Linear(1024, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,X):\n",
    "        return self.net(X)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec8a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(size=(1, 1, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6bd0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "aug=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([96,96]),\n",
    "    transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "class FashionMnist(Dataset):\n",
    "\n",
    "    def __init__(self, img_path, label_path):\n",
    "        super().__init__()\n",
    "        self.load_data_from_path(img_path, label_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.imgs[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.img_num\n",
    "\n",
    "    def load_data_from_path(self, img_path, label_path):\n",
    "        with open(img_path, 'rb') as f:\n",
    "            s = f.read()\n",
    "\n",
    "        self.img_num = int(s[4:8].hex(), 16)\n",
    "        self.imgs = torch.FloatTensor(list(iter(s[16:])))\n",
    "        # print(self.img_num,self.imgs)\n",
    "        self.imgs = torch.reshape(self.imgs, (-1, 1, 28, 28))\n",
    "        # print(self.imgs.shape)\n",
    "        with open(label_path, 'rb') as f:\n",
    "            s = f.read()\n",
    "        self.labels = torch.tensor(list(iter(s[8:])))\n",
    "        # print(self.labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_227(img,aug):\n",
    "    return aug(img).numpy().tolist()\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, labels = [], []\n",
    "    for X, y in batch:\n",
    "        inputs.append(convert_to_227(X, aug))\n",
    "        labels.append(y)\n",
    "        \n",
    "    \n",
    "    return torch.Tensor(inputs), torch.tensor(labels)\n",
    "\n",
    "train_img_path='D:/datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte'\n",
    "train_label_path='D:/datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte'\n",
    "test_img_path='D:/datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte'\n",
    "test_label_path='D:/datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte'\n",
    "\n",
    "train_data=FashionMnist(train_img_path,train_label_path)\n",
    "test_data=FashionMnist(test_img_path,test_label_path)\n",
    "train_iter=DataLoader(train_data,batch_size=16,shuffle=True,collate_fn=collate_fn)\n",
    "test_iter=DataLoader(test_data,batch_size=16,shuffle=True,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc12fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precise(test_iter,net,device):\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for X,y in test_iter:\n",
    "            total+=len(X)\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            y_hat=net(X)\n",
    "            out_put=torch.argmax(y_hat,dim=-1)\n",
    "            ans=(out_put==y)\n",
    "            correct+=ans.sum().item()\n",
    "        \n",
    "    print(correct)\n",
    "    print(f\"accuracy :{correct/total*100:>3f}% \")\n",
    "\n",
    "    \n",
    "def train(data_iter,entroy_iter,net,optimizer,lr_scheduler,loss_fn,epochs,device,epoch_data_num):\n",
    "    matrix_x,matrix_loss,entroy_loss,entroy_x=[0],[0],[],[]\n",
    "    total_loss=0\n",
    "    batchs=len(data_iter)\n",
    "    for epoch in range(epochs):\n",
    "        now_num=0\n",
    "        for X,y in data_iter:\n",
    " \n",
    "            now_num+=len(X)\n",
    "    \n",
    "            net.train()\n",
    "            \n",
    "            X,y=X.to(device),y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat=net(X)\n",
    "            loss=loss_fn(y_hat,y)\n",
    "            loss.sum().backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss+=loss.item()\n",
    "\n",
    "            matrix_x.append(matrix_x[-1]+1)\n",
    "            matrix_loss.append(total_loss/(epoch*epoch_data_num+now_num))\n",
    "            \n",
    "            print(f\"loss: {matrix_loss[-1]:>7f} now {matrix_x[-1]}/{batchs*epochs}\",end='\\r')\n",
    "            \n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        with torch.no_grad():\n",
    "            c_total_loss=0\n",
    "            test_data_num=0\n",
    "            for X,y in entroy_iter: \n",
    "                net.eval()\n",
    "                test_data_num+=len(X)\n",
    "                X,y=X.to(device),y.to(device)\n",
    "                y_hat=net(X)\n",
    "                loss=loss_fn(y_hat,y)\n",
    "                \n",
    "                c_total_loss+=loss.item()\n",
    "            \n",
    "            print(test_data_num)\n",
    "            entroy_loss.append(c_total_loss/test_data_num)\n",
    "            entroy_x.append((epoch+1)*batchs)\n",
    "        print(f\"cross entroy loss:{entroy_loss[-1]} now {epoch+1}/{epochs}\")\n",
    "        torch.save(net.state_dict(), f\"Google_epoch{epoch+6}.bin\")\n",
    "        precise(test_iter,net,device)\n",
    "\n",
    "  \n",
    "    \n",
    "    return net,matrix_x,matrix_loss,entroy_x,entroy_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e37512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 0.015182 now 3750/15000\n",
      "cross entroy loss:0.019338746465323492 now 1/4\n",
      "8883\n",
      "accuracy :88.830000% \n",
      "10000 0.014961 now 7500/15000\n",
      "cross entroy loss:0.019210604816582055 now 2/4\n",
      "8889\n",
      "accuracy :88.890000% \n",
      "10000 0.014814 now 11250/15000\n",
      "cross entroy loss:0.019152787777595222 now 3/4\n",
      "8888\n",
      "accuracy :88.880000% \n",
      "loss: 0.014700 now 13874/15000\r"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net=GoogleNet().to(device)\n",
    "net.load_state_dict(torch.load('./Google_epoch5.bin'))\n",
    "optimizer=Adam(net.parameters(),lr=0.000016)\n",
    "lr_scheduler=LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(2**epoch))\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "'''for m in net.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "'''\n",
    "_,matrix_x,matrix_loss,entroy_x,entroy_loss=train(train_iter,test_iter,net,optimizer,lr_scheduler,loss_fn,4,device,len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1629cbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538f02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
