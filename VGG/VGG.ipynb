{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f79d95",
   "metadata": {},
   "source": [
    "## VGG 网络结构\n",
    "\n",
    "![](./img/VGG.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3736923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VGG_Block(nn.Module):\n",
    "    def __init__(self,num_convs, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers=[]\n",
    "        for i in range(num_convs):\n",
    "            layers.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1))\n",
    "            \n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "            in_channels=out_channels\n",
    "        \n",
    "        layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        \n",
    "        self.net=nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    \n",
    "\n",
    "conv_arch=((2, 64), (2, 128), (3, 256), (3, 512), (2, 128))\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self,conv_arch,input_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers=[]\n",
    "        for (conv_num,out_channels) in conv_arch:\n",
    "        \n",
    "            layers.append(VGG_Block(conv_num,input_channels,out_channels))\n",
    "            input_channels=out_channels\n",
    "            \n",
    "        \n",
    "        self.net=nn.Sequential(\n",
    "            *layers,\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6272,1000),nn.ReLU(),\n",
    "            nn.Dropout(p=0.8),   \n",
    "            nn.Linear(1000,10)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        return self.net(X)\n",
    "    \n",
    "\n",
    "            \n",
    "conv_arch_1=((2, 64), (2, 128), (2, 256), (2, 512), (1, 64))\n",
    "class VGG_1(nn.Module):\n",
    "    def __init__(self,conv_arch,input_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers=[]\n",
    "        for (conv_num,out_channels) in conv_arch:\n",
    "        \n",
    "            layers.append(VGG_Block(conv_num,input_channels,out_channels))\n",
    "            input_channels=out_channels\n",
    "            \n",
    "        \n",
    "        self.net=nn.Sequential(\n",
    "            *layers,\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136,392),nn.ReLU(),\n",
    "            nn.Linear(392,10)\n",
    "        )   \n",
    "    def forward(self,X):\n",
    "        return self.net(X)\n",
    "\n",
    "conv_arch_2=((2, 64), (1, 128), (3, 256), (1, 256), (1, 64))\n",
    "class VGG_2(nn.Module):\n",
    "    def __init__(self,conv_arch,input_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers=[]\n",
    "        for (conv_num,out_channels) in conv_arch:\n",
    "        \n",
    "            layers.append(VGG_Block(conv_num,input_channels,out_channels))\n",
    "            input_channels=out_channels\n",
    "            \n",
    "        \n",
    "        self.net=nn.Sequential(\n",
    "            *layers,\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136,1000),nn.ReLU(),\n",
    "            nn.Linear(1000,256),nn.ReLU(),\n",
    "            nn.Linear(256,10)\n",
    "        )   \n",
    "        \n",
    "    def forward(self,X):\n",
    "        return self.net(X)\n",
    "\n",
    "            \n",
    "\n",
    "conv_arch_3=((3, 64), (1, 128), (1, 256), (1, 256), (1, 64))\n",
    "class VGG_3(nn.Module):\n",
    "    def __init__(self,conv_arch,input_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers=[]\n",
    "        for (conv_num,out_channels) in conv_arch:\n",
    "        \n",
    "            layers.append(VGG_Block(conv_num,input_channels,out_channels))\n",
    "            input_channels=out_channels\n",
    "            \n",
    "        \n",
    "        self.net=nn.Sequential(\n",
    "            *layers,\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136,1000),nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1000,256),nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256,10)\n",
    "        )   \n",
    "        \n",
    "    def forward(self,X):\n",
    "        return self.net(X)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed029cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6fdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "aug=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "class FashionMnist(Dataset):\n",
    "\n",
    "    def __init__(self, img_path, label_path):\n",
    "        super().__init__()\n",
    "        self.load_data_from_path(img_path, label_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.imgs[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.img_num\n",
    "\n",
    "    def load_data_from_path(self, img_path, label_path):\n",
    "        with open(img_path, 'rb') as f:\n",
    "            s = f.read()\n",
    "\n",
    "        self.img_num = int(s[4:8].hex(), 16)\n",
    "        self.imgs = torch.FloatTensor(list(iter(s[16:])))\n",
    "        # print(self.img_num,self.imgs)\n",
    "        self.imgs = torch.reshape(self.imgs, (-1, 1, 28, 28))\n",
    "        # print(self.imgs.shape)\n",
    "        with open(label_path, 'rb') as f:\n",
    "            s = f.read()\n",
    "        self.labels = torch.tensor(list(iter(s[8:])))\n",
    "        # print(self.labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_224(img,aug):\n",
    "    return aug(img).numpy().tolist()\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, labels = [], []\n",
    "    for X, y in batch:\n",
    "        inputs.append(convert_to_224(X, aug))\n",
    "        labels.append(y)\n",
    "        \n",
    "    \n",
    "    return torch.Tensor(inputs), torch.tensor(labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea542255",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path='D:/datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte'\n",
    "train_label_path='D:/datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte'\n",
    "test_img_path='D:/datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte'\n",
    "test_label_path='D:/datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4b2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=FashionMnist(train_img_path,train_label_path)\n",
    "test_data=FashionMnist(test_img_path,test_label_path)\n",
    "train_iter=DataLoader(train_data,batch_size=16,shuffle=True,collate_fn=collate_fn)\n",
    "test_iter=DataLoader(test_data,batch_size=16,shuffle=True,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601c38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precise(test_iter,net,device):\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for X,y in test_iter:\n",
    "            total+=len(X)\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            y_hat=net(X)\n",
    "            out_put=torch.argmax(y_hat,dim=-1)\n",
    "            ans=(out_put==y)\n",
    "            correct+=ans.sum().item()\n",
    "        \n",
    "    print(correct)\n",
    "    print(f\"accuracy :{correct/total*100:>3f}% \")\n",
    "\n",
    "    \n",
    "def train(data_iter,entroy_iter,net,optimizer,lr_scheduler,loss_fn,epochs,device,epoch_data_num):\n",
    "    matrix_x,matrix_loss,entroy_loss,entroy_x=[0],[0],[],[]\n",
    "    total_loss=0\n",
    "    batchs=len(data_iter)\n",
    "    for epoch in range(epochs):\n",
    "        now_num=0\n",
    "        for X,y in data_iter:\n",
    " \n",
    "            now_num+=len(X)\n",
    "    \n",
    "            net.train()\n",
    "            \n",
    "            X,y=X.to(device),y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat=net(X)\n",
    "            loss=loss_fn(y_hat,y)\n",
    "            loss.sum().backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss+=loss.item()\n",
    "\n",
    "            matrix_x.append(matrix_x[-1]+1)\n",
    "            matrix_loss.append(total_loss/(epoch*epoch_data_num+now_num))\n",
    "            \n",
    "            print(f\"loss: {matrix_loss[-1]:>7f} now {matrix_x[-1]}/{batchs*epochs}\",end='\\r')\n",
    "            \n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        with torch.no_grad():\n",
    "            c_total_loss=0\n",
    "            test_data_num=0\n",
    "            for X,y in entroy_iter: \n",
    "                net.eval()\n",
    "                test_data_num+=len(X)\n",
    "                X,y=X.to(device),y.to(device)\n",
    "                y_hat=net(X)\n",
    "                loss=loss_fn(y_hat,y)\n",
    "                \n",
    "                c_total_loss+=loss.item()\n",
    "            \n",
    "            print(test_data_num)\n",
    "            entroy_loss.append(c_total_loss/test_data_num)\n",
    "            entroy_x.append((epoch+1)*batchs)\n",
    "        print(f\"cross entroy loss:{entroy_loss[-1]} now {epoch+1}/{epochs}\")\n",
    "        torch.save(net.state_dict(), f\"Vgg_epoch{epoch+4}.bin\")\n",
    "        precise(test_iter,net,device)\n",
    "\n",
    "  \n",
    "    \n",
    "    return net,matrix_x,matrix_loss,entroy_x,entroy_loss\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96522b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net=VGG(conv_arch,1).to(device)\n",
    "net.load_state_dict(torch.load('Vgg_epoch3.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6827959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 0.013192 now 3750/3750\n",
      "cross entroy loss:0.01425676906905137 now 1/1\n",
      "9145\n",
      "accuracy :91.450000% \n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "weights_path='./epoch1.bin'\n",
    "optimizer=Adam(net.parameters(),lr=0.0000003)\n",
    "lr_scheduler=LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch+1))\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "_,matrix_x,matrix_loss,entroy_x,entroy_loss=train(train_iter,test_iter,net,optimizer,lr_scheduler,loss_fn,1,device,len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c5e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66449620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
